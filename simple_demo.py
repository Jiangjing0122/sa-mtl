from __future__ import print_function

__doc__ = """Simple demo on toy data.

In this demo, our toy data is the set of 'valley' sequences.  These are
sequences of numbers which are first decreasing and then increasing.

We train our generator via curriculum learning.  We start by only training
it to predict the next token given a groundtruth sequence via cross-entropy
loss.  As our generator learns, we start to train it directly against the
discriminator.

The discriminator always learns at the standard rate (half real examples
and half artificial examples generated by the generator).

"""

import model
import numpy as np
import tensorflow as tf
import random
import os

os.environ["CUDA_VISIBLE_DEVICES"] = "0"
print("current pid:", os.getpid())

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')
        tf.config.experimental.set_memory_growth(gpus[0], True)
        print("should be ok...right?")
    except RuntimeError as e:
        print(e)
else:
    print("gpu unlimited?")

tf.compat.v1.disable_v2_behavior()

NUM_EMB = 4
EMB_DIM = 5
HIDDEN_DIM = 10
SEQ_LENGTH = 5
START_TOKEN = 0

EPOCH_ITER = 1000
CURRICULUM_RATE = 0.03  # how quickly to move from supervised training to unsupervised
TRAIN_ITER = 100000  # generator/discriminator alternating
D_STEPS = 2  # how many times to train the discriminator per generator step
LEARNING_RATE = 0.01 * SEQ_LENGTH
SEED = 88


def train_epoch(sess, trainable_model, num_iter, proportion_supervised, g_steps, d_steps, next_sequence, words=None):
    """Perform training for model.

    sess: tensorflow session
    trainable_model: the model
    num_iter: number of iterations
    proportion_supervised: what proportion of iterations should the generator
        be trained in a supervised manner (rather than trained via discriminator)
    g_steps: number of generator training steps per iteration
    d_steps: number of discriminator training steps per iteration
    next_sequence: function that returns a groundtruth sequence
    words:  array of words (to map indices back to words)

    """
    supervised_g_losses = [0]  # we put in 0 to avoid empty slices
    unsupervised_g_losses = [0]  # we put in 0 to avoid empty slices
    d_losses = [0]
    expected_rewards = [[0] * trainable_model.sequence_length]
    supervised_correct_generation = [0]
    unsupervised_correct_generation = [0]
    supervised_gen_x = None
    unsupervised_gen_x = None
    print('running %d iterations with %d g steps and %d d steps' % (num_iter, g_steps, d_steps))
    print('of the g steps, %.2f will be supervised' % proportion_supervised)
    for it in range(num_iter):
        for _ in range(g_steps):
            if random.random() < proportion_supervised:#supervision step
                seq = next_sequence()
                _, g_loss, g_pred = trainable_model.pretrain_step(sess, seq)
                supervised_g_losses.append(g_loss)
                supervised_gen_x = np.argmax(g_pred, axis=1)
            else:
                _, _, g_loss, expected_reward, unsupervised_gen_x = trainable_model.train_g_step(sess)
                expected_rewards.append(expected_reward)
                unsupervised_g_losses.append(g_loss)

        for _ in range(d_steps):
            if random.random() < 0.5:
                seq = next_sequence()
                _, d_loss = trainable_model.train_d_real_step(sess, seq)
            else:
                _, d_loss = trainable_model.train_d_gen_step(sess)
            d_losses.append(d_loss)

    print('epoch statistics:')
    print('>>>> discriminator loss:', np.mean(d_losses))
    print('>>>> generator loss:', np.mean(supervised_g_losses), np.mean(unsupervised_g_losses))
    print('>>>> sampled generations (supervised, unsupervised):', )
    print([words[x] if words else x for x in supervised_gen_x] if supervised_gen_x is not None else None, )
    print([words[x] if words else x for x in unsupervised_gen_x] if unsupervised_gen_x is not None else None)
    print('>>>> expected rewards:', np.mean(expected_rewards, axis=0))


def get_trainable_model():
    return model.GRU(NUM_EMB, EMB_DIM, HIDDEN_DIM, SEQ_LENGTH, START_TOKEN, learning_rate=LEARNING_RATE)


def verify_sequence(seq):  # return false for spikes
    downhill = True
    prev = NUM_EMB
    for tok in seq:
        if tok == START_TOKEN:
            return False
        if downhill:
            if tok > prev:
                downhill = False
        elif tok < prev:
            return False
        prev = tok
    return True


def get_random_sequence():
    """Returns random valley sequence."""
    tokens = set(range(NUM_EMB))
    tokens.discard(START_TOKEN)
    tokens = list(tokens)

    pivot = int(random.random() * SEQ_LENGTH)
    left_of_pivot = []
    right_of_pivot = []
    for i in range(SEQ_LENGTH):
        tok = random.choice(tokens)
        if i <= pivot:
            left_of_pivot.append(tok)
        else:
            right_of_pivot.append(tok)

    left_of_pivot.sort(reverse=True)
    right_of_pivot.sort(reverse=False)

    return left_of_pivot + right_of_pivot


def test_sequence_definition():
    for _ in range(1000):
        assert verify_sequence(get_random_sequence())


def main():
    random.seed(SEED)
    np.random.seed(SEED)

    # get_trainable_model()
    trainable_model = model.GRU(NUM_EMB, EMB_DIM, HIDDEN_DIM, SEQ_LENGTH, START_TOKEN, learning_rate=LEARNING_RATE)
    sess = tf.compat.v1.Session()
    sess.run(tf.compat.v1.global_variables_initializer())

    print('training')
    for epoch in range(TRAIN_ITER // EPOCH_ITER):
        print('epoch', epoch)
        proportion_supervised = max(0.0, 1.0 - CURRICULUM_RATE * epoch)
        train_epoch(sess, trainable_model, EPOCH_ITER, proportion_supervised=proportion_supervised,
                    g_steps=1, d_steps=D_STEPS, next_sequence=get_random_sequence)


if __name__ == '__main__':
    test_sequence_definition()
    main()
